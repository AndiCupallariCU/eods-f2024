{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Homework 2\n",
    "\n",
    "## [Name] - [UNI]\n",
    "\n",
    "### Due: Monday Nov 18th @ 11:59pm ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will be performing model evaluation, model selection and hyperparameter tuning in both a regression and classification setting.\n",
    "\n",
    "We will be working with a small set of home sales data as we might see on a real-estate website.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Replace Name and UNI in the first cell and filename\n",
    "- Follow the comments below and fill in the blanks (\\_\\_\\_\\_) to complete.\n",
    "- Please **'Restart and Run All'** prior to submission.\n",
    "- **Save pdf in Landscape** and **check that all of your code is shown** in the submission.\n",
    "- When submitting in Gradescope, be sure to **select which page corresponds to which question.**\n",
    "\n",
    "Out of 50 points total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. (2pts total) Homework Submission\n",
    "\n",
    "# (1pt) The homework should be spread over multiple pdf pages, not one single pdf page\n",
    "# (1pt) When submitting, assign each question to the pdf page where the solution is printed.\n",
    "#        If there is no print statement for a question, assign the question to the first pdf \n",
    "#        page where the code for the question is visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. (2pts) Set up our environment with common libraries and plot settings.\n",
    "#    Note: generally we would do all of our imports here but some imports\n",
    "#    have been left till later where they are used.\n",
    "\n",
    "# Import numpy as np, pandas as pd, matplotlib.pyplot as plt and seaborn as sns\n",
    "# Note: use as many lines of code as necessary\n",
    "____\n",
    "\n",
    "# Set the seaborn style to 'darkgrid'\n",
    "____\n",
    "\n",
    "# Execute the matplotlib magic function to ensure plots are displayed inline\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 1 we will try to predict a real value home sale price using several models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. (4pts) Load and prepare our data.\n",
    "\n",
    "# Read in the csv file ../data/home_sales.csv \n",
    "#   Use pandas .read_csv() with default parameter settings\n",
    "#   Contains the columns\n",
    "#     SqFtLiving1e3 : square feet of living space in 1000s of sqft.\n",
    "#     SqFtLot1e3    : square feet of the lot in 1000s of sqft.\n",
    "#     NumBedrooms   : number of bedrooms\n",
    "#     SalePrice1e5  : sale price in $10_000s\n",
    "# Store in df\n",
    "df = ____\n",
    "\n",
    "# Create a dataframe X which contains these 3 columns from df:\n",
    "#  'SqFtLiving1e3','SqFtLot1e3','NumBedrooms'\n",
    "X = ____\n",
    "\n",
    "# Create a series y_r which contains only the column SalePrice1e5\n",
    "#    Note: the '_r' is for our regression target\n",
    "y_r = ____\n",
    "\n",
    "# Check that X and y_r are the correct shape (500 rows)\n",
    "assert X.shape == (500,3)\n",
    "assert y_r.shape == (500,)\n",
    "\n",
    "# To confirm that all features of X are similar in scale display the .describe() of X\n",
    "#   Use .round(2) to round all values to a precision of 2\n",
    "____\n",
    "\n",
    "# To get a sense of the distribution of the target, plot a histogram of y_r using sns.histplot()\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. (3pts) Create a training and test/held-aside set for regression\n",
    "\n",
    "# Import train_test_split from sklearn\n",
    "____\n",
    "\n",
    "# Split X and y_r using train_test_split\n",
    "#   Use 80% train and 20% test\n",
    "#   Use random_state=512 for grading consistency.\n",
    "#   Store in X_train_r, X_test_r, y_train_r, y_test_r\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = ____\n",
    "\n",
    "# Print out the the length of y_test_r divided by the length y_r to confirm our test set size.\n",
    "print(f'proportion of data in test set: {____}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1 Baseline Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. (2pts) Create a DummyRegressor and fit on the training set.\n",
    "\n",
    "# Import the DummyRegressor model from sklearn \n",
    "____\n",
    "\n",
    "# Instantiate a DummyRegessor model with strategy=\"mean\" (the default)\n",
    "# Store in dummy_r\n",
    "dummy_r = ____\n",
    "\n",
    "# Train the DummyRegressor on the regression training set\n",
    "____\n",
    "\n",
    "# Calculate the training set R^2 score of the DummyRegressor\n",
    "dummy_r_training_r2 = ____\n",
    "\n",
    "# Recall that this should equal 0\n",
    "print(f'dummy training set R^2: {dummy_r_training_r2.round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 Linear Regression and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. (2pts) Train a Linear Regression model and calculate training set R^2.\n",
    "\n",
    "# Import the LinearRegression model from sklearn\n",
    "____\n",
    "\n",
    "# Instantiate a LinearRegression model \n",
    "#    with default arguments \n",
    "#    and fit on the training set\n",
    "# Store in lr\n",
    "lr = ____\n",
    "\n",
    "# Calculate the training set R^2 of the LinearRegression model\n",
    "lr_training_r2 = ____\n",
    "\n",
    "# This should be better than our dummy R^2\n",
    "print(f'lr training set R^2: {lr_training_r2.round(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. (2pts) Use 5-fold Cross Validation to get a sense of the variation \n",
    "#    of Liner Regression R^2 performance on the training set.\n",
    "\n",
    "# Import cross_val_score from sklearn.\n",
    "____\n",
    "\n",
    "# Generate 5-fold cross-validation R^2 scores \n",
    "#    for a LinearRegression model with default arguments\n",
    "#    on the training set\n",
    "#    Use 5-folds (the default)\n",
    "# Store in lr_cv_scores\n",
    "lr_cv_scores = ____\n",
    "\n",
    "# Print out the R^2 scores found by cross_val_score rounded to a precision of 2\n",
    "#   we should 5 floats between .3 and .6\n",
    "lr_cv_scores.round(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. (1pts) Calculate mean training cv R^2 score +- 2 std. deviations\n",
    "\n",
    "# Calculate the mean training cross validation score using the scores created above\n",
    "lr_cv_mean = ____\n",
    "\n",
    "# Calculate 2 standard deviations of the cross validation scores\n",
    "lr_cv_2std = ____\n",
    "\n",
    "# Print out the mean R^2 +- 2 standard variations for the LinearRegression model\n",
    "#   each rounded to a precision of 2\n",
    "print(f'lr mean cv r2: {lr_cv_mean.round(2)} +- {lr_cv_2std.round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3 Overfitting with a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. (2pts) Create a DecisionTreeRegressor and fit on the training set.\n",
    "\n",
    "# Import the DecisionTreeRegressor model from sklearn \n",
    "____\n",
    "\n",
    "# Instantiate a DecisionTreeRegressor model \n",
    "#    with max_depth=10\n",
    "#    and fit on the training set\n",
    "# Store in dtr\n",
    "dtr = ____\n",
    "\n",
    "# Calculate the training set R^2 score of the DecisionTreeRegressor\n",
    "dtr_training_r2 = ____\n",
    "\n",
    "# This should be a high R^2 value\n",
    "print(f'dummy training set R^2: {dtr_training_r2.round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3 Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. (2pts) Evaluate performance of our trained models on the test set.\n",
    "\n",
    "# Calculate R^2 on the test set using the previously trained models\n",
    "#   We do not need to fit the models again on the training set data\n",
    "dummy_r_test_r2 = ____\n",
    "\n",
    "lr_test_r2 = ____\n",
    "\n",
    "dtr_test_r2 = ____\n",
    "\n",
    "print(f'dummy test R2 : {dummy_r_test_r2.round(2): .2f}') # this may be less than 0\n",
    "print(f'   lr test R2 : {lr_test_r2.round(2): .2f}')      # this should within the lr training cv += 2 std devs\n",
    "print(f'  dtr test R2 : {dtr_test_r2.round(2): .2f}')     # this should show overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build several models to classify low vs. high sale price, create a validation curve and perform grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Classification Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reuse the same dataset, we'll first create a binary target for \n",
    "#    classification by thresholding at the mean of our SalePrice1e5\n",
    "\n",
    "# The classes are:\n",
    "#    Low  SalePrice1e5 = 0\n",
    "#    High SalePrice1e5 = 1\n",
    "\n",
    "y_c = (df.SalePrice1e5 > df.SalePrice1e5.mean()).astype(int)\n",
    "\n",
    "# Print out the class labels with counts and note it's an imbalanced binary classification problem\n",
    "pd.Series(y_c).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1 Create Classification Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. (4pts) Create a training and test/held-aside set for classifiction\n",
    "\n",
    "# Split X (the same X as before) and the new y_c using train_test_split\n",
    "#   Use 80% train and 20% test\n",
    "#   Stratify according to y_c so class proportions are the same in train and test\n",
    "#   Use random_state=512 for grading consistency.\n",
    "#   Store in X_train_c, X_test_c, y_train_c, y_test_c\n",
    "____\n",
    "\n",
    "# Print out the proportion of Low values (label of 0) in y_c rounded to a precision of 2\n",
    "print(f'proportion of Low values: {____}') # should be near 60%\n",
    "\n",
    "# Assert that train and test have similar class proportions.\n",
    "# Find the proportion of Low (0) values in both y_train_c and y_test_c and \n",
    "#    assert that the absolute difference of these proportions is less than .01\n",
    "assert ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2 Measure Classification Baseline Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. (2pts)  Create a Dummy Classifier and confirm the expected performance on the training set.\n",
    "\n",
    "# Import DummyClassifier from sklearn\n",
    "____\n",
    "\n",
    "# Instantiate a DummyClassifier with strategy=\"prior\" (default) \n",
    "#    and fit on the the classification training set\n",
    "# Store in dummy_c\n",
    "dummy_c = ____\n",
    "\n",
    "# Print the trained DummyClassifier accuracy on the training set rounded to a precision of 2\n",
    "#   It should match the proportion of Low values we saw above.\n",
    "print(f'dummy training set accuracy: {____}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3  Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. (2pts) It's good practice to start with a \"simple\" model.\n",
    "#     Train and calculate 5-fold cv training set accuracy for a Logistic Regression Classifier.\n",
    "\n",
    "# Import LogisticRegression from sklearn\n",
    "____\n",
    "\n",
    "# Generate 5-fold cross validation accuracy on the training set\n",
    "#    using LogisticRegression with default hyperparameters\n",
    "# Store as logr_cv_scores\n",
    "logr_cv_scores = ____\n",
    "\n",
    "# Print out the mean cv accuracy for the LogisticRegression model rounded to a precision of 2\n",
    "print(f'logr mean cv accuracy: {____}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.4 GradientBoosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. (2pts) Now let's try a more complex model.\n",
    "#     Train and calculate 5-fold cv accuracy \n",
    "#     for a GradientBoosting model using the training set.\n",
    "\n",
    "# Import the GradientBoostingClassifier model from sklearn\n",
    "____\n",
    "\n",
    "# Calculate 5-fold cv training set accuracy scores \n",
    "#   for a GradientBoostingClassifier\n",
    "#       with 50 trees (n_estimators=50)\n",
    "#       with max_depth=10\n",
    "# This time call cross_val_score with n_jobs=-1 (use one core for each fold) to speed up the cv calculations\n",
    "# Store in gbc_cv_scores\n",
    "gbc_cv_scores = ____\n",
    " \n",
    "# Print out the mean cv accuracy for the GradientBoostingClassifier model rounded to a precision of 2\n",
    "#   Should be lower than logr above (overfitting in each fold?)\n",
    "print(f'gbc mean cv accuracy: {____}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.5 GradientBoosting and Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. (4pts) Let's investigate how the depth of trees (max_depth) affects performance.\n",
    "#     Generate a validation curve for tree depths in the GradientBoosting model.\n",
    "\n",
    "# Import the validation_curve function from sklearn\n",
    "____\n",
    "\n",
    "# In the GradientBoostingClassifier model, the depth of trees is set via max_depth\n",
    "# Create a list depths that contains the values 1,2,3,5,10\n",
    "depths = ____\n",
    "\n",
    "# Generate the train_scores and test_scores for max_depth at different maximum depths\n",
    "#   Use the validation_curve function\n",
    "#   Use a GradientBoostingClassifier with n_estimators=50 trees\n",
    "#   Use our training set X_train_c, y_train_c\n",
    "#   Use the 'max_depth' parameter as the param_name to vary\n",
    "#   Use the depths list created above as the parameter range\n",
    "#   Use 3-fold cross validation (reducing to 3 to speed things up)\n",
    "#   Use n_jobs=-1 to speed things up\n",
    "#   Use the default accuracy scoring as the scoring metric\n",
    "# Store the results in train_scores,test_scores\n",
    "train_scores,test_scores = ____\n",
    "\n",
    "# print the training set scores generated by validation_curve, rounded to a precision of 2\n",
    "#   we should see 5 rows by 3 columns of numbers between 0 and 1\n",
    "train_scores.round(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. (5pts) Plot the validation curves generated above\n",
    "\n",
    "# train_scores and test_scores each contain a 2-D array of values\n",
    "#   For each depth (rows) there are 3 scores (columns), one for each fold\n",
    "#   Take the mean for each depth across folds (columns or axis=1) \n",
    "#      and store in mean_train_scores and mean_test_scores\n",
    "mean_train_scores = ____\n",
    "mean_test_scores = ____\n",
    "\n",
    "assert mean_train_scores.shape == (5,) # There should now be 5 floats, one per row, and no columns\n",
    "assert mean_test_scores.shape == (5,)\n",
    "\n",
    "# Create a pandas DataFrame by passing in \n",
    "#   a dictionary of string:list pairs with\n",
    "#     keys: 'mean_train_scores','mean_test_scores'\n",
    "#        mapping to (respectively)\n",
    "#     values: mean_train_scores, mean_test_scores\n",
    "#   and with the DataFrame index=depths\n",
    "# Store in df_val_scores\n",
    "df_val_scores = ____\n",
    "\n",
    "# Display df_val_scores with values rounded to a precision of 2\n",
    "#   We should see a dataframe with 5 rows and 2 columns\n",
    "#   The row labels should be our depths\n",
    "#   The columns should be mean_train_scores and mean_test_scores\n",
    "#   The 10 score values should be between 0 and 1\n",
    "display(df_val_scores.round(2))\n",
    "\n",
    "# Plot the values in df_val_scores as 2 lines on the same plot\n",
    "#   Use Pandas .plot() with kind='line' (the default)\n",
    "#   Catch the returned matplotlib axis in ax\n",
    "#   Using ax, label the x-axis as \"max_depth\" \n",
    "#     and the y-axis as \"mean accuracy\"\n",
    "#   Note that as depth increases, both train and test accuracy increase (slightly) and then begin to diverge\n",
    "ax = ____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.6 GradientBoosting and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. (5pts) Above we are looking at tuning a single hyperparameter (max_depth).\n",
    "#     Now let's tune two hyperparameters at the same time.\n",
    "#     Perform 3-fold cross validated grid search over \"number of trees\" and \"tree depth\".\n",
    "\n",
    "# Import GridSearchCV from sklearn\n",
    "____\n",
    "\n",
    "# Create the grid of parameters to test as a dictionary\n",
    "#   The parameter settings to try are \n",
    "#   'n_estimators':[10,50,100,200],'max_depth':[1,2,3,5,10]\n",
    "param_grid = ____\n",
    "\n",
    "# Instantiate and fit GridSearchCV on the classification training set\n",
    "#   Use GradientBoostingClassifier with default arguments\n",
    "#   Use the param_grid parameter grid defined above\n",
    "#   Use 3-folds\n",
    "#   Use default scoring (accuracy)\n",
    "#   Use refit=True (default) so the model is retrained on the entire training set\n",
    "#   Set n_jobs=-1 to use all cores\n",
    "# Store the fitted (on the training set) GridSearchCV in gbc_gscv\n",
    "gbc_gscv = ____\n",
    "\n",
    "# Print out the best the best hyperparameter setting found (best_params_) \n",
    "#    and the mean accuracy they produced (best_score_)\n",
    "print(f'gbc best hyperparams      : {____}')\n",
    "print(f'gbc best mean cv accuracy : {____}')\n",
    "\n",
    "# Note that you may get different answers on different runs due to \n",
    "#   the random cv splits used at each grid point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.7 Evaluate on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. (4pts) Evaluate the best model on the test set\n",
    "\n",
    "# Which of our models has the highest training set cv accuracy?\n",
    "#   gbc_gscv : the GradientBoostingClassifier model with hyperparameters chosen by GridSearch\n",
    "#   logr     : the LogisticRegression model\n",
    "# If performance is the same on both models put \"no difference\"\n",
    "print('best model found: ____')\n",
    "\n",
    "# To see how each of our models would generalize to new data,\n",
    "#     calculate the **test set** accuracy for each of our trained models\n",
    "\n",
    "# First, instantiate and train a new LogisticRegression model with default settings on the training set.\n",
    "#   Note that, while we did train a LogisticRegression model several times when \n",
    "#   calculating the cross-validation accuracy, we never trained it on the full training set\n",
    "# Store in logr\n",
    "logr = ____\n",
    "\n",
    "# Find the test set accuracy of both of our trained models\n",
    "# Note that, since we used refit=True when doing grid search on the GradientBoostingClassifier,\n",
    "#   we can use gbc_gscv.score() without retraining\n",
    "logr_test_acc = ____\n",
    "gbc_test_acc = ____\n",
    "\n",
    "print(f'logr test acc     : {logr_test_acc.round(2)}')\n",
    "print(f'gbc_gscv test acc : {gbc_test_acc.round(2)}')\n",
    "\n",
    "# TO THINK ABOUT, BUT DON'T NEED TO ANSWER:\n",
    "# Did the model we chose have the best test set performance?\n",
    "# Is it guaranteed that the model with the best performance on the training set will have the best test set score?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eods-f22",
   "language": "python",
   "name": "eods-f22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
